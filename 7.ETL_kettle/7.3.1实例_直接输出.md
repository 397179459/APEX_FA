### 7.3 实例
我也是初学者，所以很多组件也没用过，不能给大家详细地讲清楚，基本就是**自己在网上查**，所以我直接给大家用实例讲，具体感兴趣的可以慢慢去研究。
#### 7.3.1 直接输入输出
![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/311.png)
这是最常见的一种转换方式，就是一个表输入——>表输出，十分高效，但是会有个问题：

---
输入表：

字段1|字段2
--|--
A|aa
B|bb
---
假如输出表是空的，第一次转换是完全没问题的，表完整的导入到本地，但是如果输入表新增了数据：

输入表：

字段1|字段2
--|--
A|aa
B|bb
C|cc
---
那么在执行第二次转换后本地表就会变成：

字段1|字段2
--|--
A|aa
B|bb
A|aa
B|bb
C|cc
这显然不是我们想要的结果，所以就必须要有相应的对策(以下只是我摸索出来的三种方案，可能还有其他的方案我没想到)：
* 方案一：条件筛选，每次从数据库获取的数据是有特征的，比如这里的实例用的一种方法就是**每次根据时间筛选(WHERE ...TIME ... = SYSDATE-2)**，这样每次选取的数据就是不会重复的。
在数据量比较大的时候，这种方案是最优的，每次在流(流相当于送快递的车)中的数据不会很多，同时直接输出也很快；但是有个问题是这种方案，假如今天8:00已经执行过了，你就不要去动它了，如果你又想测试一下，再去点一下run，那么数据就会出现重复了，所以只适合自动任务
* 方案二：把"输出"组件换成"插入/更新",下一个实例会详细讲
* 方案三：每次执行转换之前把输出表**清空**，然后再直接输出，与第一种方案相比，这个方案你可以自动运行，也可以随时run，都不会出现重复，因为每次输出之前都会把输出表清空然后再完整地"复制"过去，这种方案适用于数据量比较小的情况，
**如果流中的数据是百万千万级别的**，这种方案显然会成为你的*性能瓶颈*，执行效率肯定是没有其他两种快的

----
### 实例：
#### 输入

选择要连接的数据库，如果你熟悉SQL语句就可以直接自己编辑；不过我推荐使用第二种方法：点击"获取SQL查询语句",选择对应的表，然后再自己对SQL语句进行修改，一是因为美观，二是有的字段很长，浪费时间还容易敲错；
SQL写好之后可以"预览"一下获取的数据符不符合预期。

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/312.png)
#### 输出

选择数据库以及模式，目标表可以提前创建好，也可以直接输入一个名称，然后点击下面的"SQL"，软件会自动帮你写好建表语句，你只需要执行就行了(这个功能很强大)，一个简单的转换就完成了。

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/313.png)

#### 作业job

作业主要是用来实现自动运行的，在"START"组件设置定期任务的间隔"，在"转换"里设置执行你之前创建保存好的转换。

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/316.png)

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/317.png)

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/318.png)

---
这里没有用到方案三，但是我这里对之前的转换做了一点优化，思路是和方案三一致的，
有一个输出到本地表的数据很多(快到千万级了，我实测查询470W+的数据是1分钟左右)，我们本地其实并不需要保存这么多数据，很多数据都是很早之前的，所以我这里在转换之前增加了一个清空250天前的步骤，思路跟方案三是一致的：

![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/314.png)
![](https://github.com/397179459/APEX_FA/blob/master/img/7.kettle/315.png)
